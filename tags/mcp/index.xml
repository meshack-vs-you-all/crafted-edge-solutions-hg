<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>MCP on Crafted Edge Solutions</title><link>https://meshack-vs-you-all.github.io/crafted-edge-solutions-hg/tags/mcp/</link><description>Recent content in MCP on Crafted Edge Solutions</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 05 Feb 2026 10:00:00 +0000</lastBuildDate><atom:link href="https://meshack-vs-you-all.github.io/crafted-edge-solutions-hg/tags/mcp/index.xml" rel="self" type="application/rss+xml"/><item><title>MCP Client for Ollama — Local AI Developer Tool</title><link>https://meshack-vs-you-all.github.io/crafted-edge-solutions-hg/case-studies/mcp-client-ollama/</link><pubDate>Thu, 05 Feb 2026 10:00:00 +0000</pubDate><guid>https://meshack-vs-you-all.github.io/crafted-edge-solutions-hg/case-studies/mcp-client-ollama/</guid><description>&lt;h2 id="the-challenge"&gt;The Challenge
&lt;/h2&gt;&lt;p&gt;Developers working with the Model Context Protocol (MCP) needed a way to test and interact with MCP servers without relying on cloud-hosted LLMs. Existing tools were heavy, required API keys, and didn&amp;rsquo;t support local models.&lt;/p&gt;
&lt;h2 id="our-solution"&gt;Our Solution
&lt;/h2&gt;&lt;p&gt;We built the &lt;strong&gt;MCP Client for Ollama&lt;/strong&gt;, a powerful terminal-based user interface (TUI) designed for interacting with MCP servers using locally-hosted LLMs through Ollama.&lt;/p&gt;
&lt;h3 id="technical-architecture"&gt;Technical Architecture
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Core:&lt;/strong&gt; Python with rich TUI framework&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LLM Backend:&lt;/strong&gt; Ollama integration for running models locally&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MCP Protocol:&lt;/strong&gt; Full MCP client implementation with tool calling support&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Architecture:&lt;/strong&gt; Async-first design for responsive streaming&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="key-features"&gt;Key Features
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Agent Mode&lt;/strong&gt; — Autonomous task execution with multi-step reasoning&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dynamic Model Switching&lt;/strong&gt; — Switch between Ollama models on the fly&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tool Management&lt;/strong&gt; — Discover, inspect, and invoke MCP tools&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Streaming Responses&lt;/strong&gt; — Real-time token streaming for responsive UX&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Session Management&lt;/strong&gt; — Conversation history and context persistence&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Rich TUI&lt;/strong&gt; — Syntax highlighting, progress bars, and formatted output&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="results"&gt;Results
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Zero&lt;/strong&gt; cloud API costs — runs entirely on local hardware&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Open source&lt;/strong&gt; — Community-driven development and contributions&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cross-platform&lt;/strong&gt; — Works on Linux, macOS, and WSL&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="tech-stack"&gt;Tech Stack
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;Python&lt;/code&gt; &lt;code&gt;Ollama&lt;/code&gt; &lt;code&gt;MCP Protocol&lt;/code&gt; &lt;code&gt;Async/Await&lt;/code&gt; &lt;code&gt;Rich TUI&lt;/code&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;&lt;a class="link" href="https://github.com/meshack-vs-you-all/mcp-client-for-ollama" target="_blank" rel="noopener"
 &gt;View on GitHub →&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description></item></channel></rss>